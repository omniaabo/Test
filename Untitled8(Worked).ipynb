{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Bj0hD4_NYzLT",
        "OteoOuPvZEyN",
        "-7ObN4lE9MtP",
        "7jchUeIAbfjb",
        "ctcQ2G4PsBHW",
        "iGtwZaz86myz",
        "283WOuAHaJ7G",
        "CwbJool-uYMo",
        "hrb2XGhwnFnd"
      ],
      "authorship_tag": "ABX9TyNJ9OvF8Mc76thPUgeOE+53",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omniaabo/Test/blob/main/Untitled8(Worked).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cblGtXcYA5ME"
      },
      "outputs": [],
      "source": [
        "#t\n",
        "import matplotlib.pyplot\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from operator import length_hint "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Shortest** **Path**"
      ],
      "metadata": {
        "id": "Bj0hD4_NYzLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "#shortest path\n",
        "\"\"\"\n",
        "Created on Sun Aug  7 14:11:56 2022\n",
        "\n",
        "@author: hp\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        " \n",
        "class Graph(object):\n",
        "    def __init__(self, nodes, init_graph):\n",
        "        self.nodes = nodes\n",
        "        self.graph = self.construct_graph(nodes, init_graph)\n",
        "        \n",
        "    def construct_graph(self, nodes, init_graph):\n",
        "        \n",
        "        #This method makes sure that the graph is symmetrical. In other words, if there's a path from node A to B with a value V, there needs to be a path from node B to node A with a value V.\n",
        "       \n",
        "        graph = {}\n",
        "        for node in nodes:\n",
        "            graph[node] = {}\n",
        "        \n",
        "        graph.update(init_graph)\n",
        "        \n",
        "        for node, edges in graph.items():\n",
        "            for adjacent_node, value in edges.items():\n",
        "                if graph[adjacent_node].get(node, False) == False:\n",
        "                    graph[adjacent_node][node] = value\n",
        "                    \n",
        "        return graph\n",
        "    \n",
        "    def get_nodes(self):\n",
        "        \"Returns the nodes of the graph.\"\n",
        "        return self.nodes\n",
        "    \n",
        "    def get_outgoing_edges(self, node):\n",
        "        \"Returns the neighbors of a node.\"\n",
        "        connections = []\n",
        "        for out_node in self.nodes:\n",
        "            if self.graph[node].get(out_node, False) != False:\n",
        "                connections.append(out_node)\n",
        "        return connections\n",
        "    \n",
        "    def value(self, node1, node2):\n",
        "        \"Returns the value of an edge between two nodes.\"\n",
        "        return self.graph[node1][node2]\n",
        "\n",
        "\n",
        "def dijkstra_algorithm(graph, start_node):\n",
        "    unvisited_nodes = list(graph.get_nodes())\n",
        " \n",
        "    # We'll use this dict to save the cost of visiting each node and update it as we move along the graph   \n",
        "    shortest_path = {}\n",
        " \n",
        "    # We'll use this dict to save the shortest known path to a node found so far\n",
        "    previous_nodes = {}\n",
        " \n",
        "    # We'll use max_value to initialize the \"infinity\" value of the unvisited nodes   \n",
        "    max_value = sys.maxsize\n",
        "    for node in unvisited_nodes:\n",
        "        shortest_path[node] = max_value\n",
        "    # However, we initialize the starting node's value with 0   \n",
        "    shortest_path[start_node] = 0\n",
        "    count=0\n",
        "    # The algorithm executes until we visit all nodes\n",
        "    while unvisited_nodes:\n",
        "        # The code block below finds the node with the lowest score\n",
        "        current_min_node = None\n",
        "        for node in unvisited_nodes: # Iterate over the nodes\n",
        "            if current_min_node == None:\n",
        "                current_min_node = node\n",
        "            elif shortest_path[node] < shortest_path[current_min_node]:\n",
        "                current_min_node = node\n",
        "                \n",
        "        # The code block below retrieves the current node's neighbors and updates their distances\n",
        "        neighbors = graph.get_outgoing_edges(current_min_node)\n",
        "        for neighbor in neighbors:\n",
        "            tentative_value = shortest_path[current_min_node] + graph.value(current_min_node, neighbor)\n",
        "            if tentative_value < shortest_path[neighbor]:\n",
        "                shortest_path[neighbor] = tentative_value\n",
        "                # We also update the best path to the current node\n",
        "                previous_nodes[neighbor] = current_min_node\n",
        " \n",
        "        # After visiting its neighbors, we mark the node as \"visited\"\n",
        "        unvisited_nodes.remove(current_min_node)\n",
        "    \n",
        "    return previous_nodes, shortest_path\n",
        "\n",
        "def print_result(previous_nodes, shortest_path, start_node, target_node):\n",
        "    path = []\n",
        "    node = target_node\n",
        "    \n",
        "    while node != start_node:\n",
        "        path.append(node)\n",
        "        node = previous_nodes[node]\n",
        " \n",
        "    # Add the start node manually\n",
        "    path.append(start_node)\n",
        "    \n",
        "    #print(\"We found the following best path with a value of {}.\".format(shortest_path[target_node]))\n",
        "    #print(\" -> \".join(reversed(path)))\n",
        "    #print(f\"Number Of Hops = {len(path)}\")\n",
        "    return format(shortest_path[target_node]),len(path)\n",
        "\n",
        "def ShortestPath(start,end):\n",
        "    nodes = [\"ATLAM5\", \"ATLAng\", \"CHINng\", \"DNVRng\", \"HSTNng\", \"IPLSng\", \"KSCYng\", \"LOSAng\", \"NYCMng\", \"SNVAng\", \"STTLng\", \"WASHng\"]\n",
        "    \n",
        "     \n",
        "    init_graph = {}\n",
        "    for node in nodes:\n",
        "        init_graph[node] = {}\n",
        "        \n",
        "    init_graph[\"ATLAM5\"][\"ATLAng\"] = 0.6618242212428414\n",
        "    init_graph[\"ATLAng\"][\"HSTNng\"] = 5.395735790861154\n",
        "    init_graph[\"ATLAng\"][\"IPLSng\"] = 2.950379471305515\n",
        "    init_graph[\"ATLAng\"][\"WASHng\"] = 4.496181432177612\n",
        "    init_graph[\"CHINng\"][\"IPLSng\"] = 1.2954971045263282\n",
        "    init_graph[\"CHINng\"][\"NYCMng\"] = 5.724346541223465\n",
        "    init_graph[\"DNVRng\"][\"KSCYng\"] = 3.720073798163767               \n",
        "    init_graph[\"DNVRng\"][\"SNVAng\"] = 7.569993244146227               \n",
        "    init_graph[\"DNVRng\"][\"STTLng\"] = 7.854873360987624\n",
        "    init_graph[\"HSTNng\"][\"KSCYng\"] = 5.134158303429244\n",
        "    init_graph[\"HSTNng\"][\"LOSAng\"] = 10.964808201671724               \n",
        "    init_graph[\"IPLSng\"][\"KSCYng\"] = 4.506317299225467\n",
        "    init_graph[\"LOSAng\"][\"SNVAng\"] = 2.518247042266586\n",
        "    init_graph[\"NYCMng\"][\"WASHng\"] = 1.674941676397201\n",
        "    init_graph[\"SNVAng\"][\"STTLng\"] = 5.6799681106984 \n",
        "    \n",
        "    '''\n",
        "    #init_graph[\"Moscow\"][\"Belgrade\"] = 5\n",
        "    #init_graph[\"Moscow\"][\"Athens\"] = 4\n",
        "    #init_graph[\"Athens\"][\"Belgrade\"] = 1\n",
        "    #init_graph[\"Rome\"][\"Berlin\"] = 2\n",
        "    #init_graph[\"Rome\"][\"Athens\"] = 2\n",
        "    '''\n",
        "    graph = Graph(nodes, init_graph)\n",
        "    previous_nodes, shortest_path = dijkstra_algorithm(graph=graph, start_node= start)\n",
        "    result = print_result(previous_nodes, shortest_path, start_node= start, target_node= end)\n",
        "   \n",
        "    return result\n",
        "\n",
        "def BestControllerLocation(lista):\n",
        "    BestPath = 200.9999999 ###########################################\n",
        "    for i in lista:\n",
        "        global nwl\n",
        "        global ControllerLocation\n",
        "        global Hops\n",
        "        global PropagationDelay\n",
        "        totalweight = 0\n",
        "        elementsweight = []\n",
        "        delay=[]\n",
        "        newlista = lista.copy()\n",
        "        newlista.remove(i)\n",
        "        count=[]\n",
        "        for j in newlista:\n",
        "            w,c= ShortestPath(i,j)\n",
        "            totalweight+=float(w)\n",
        "            count.append(c)\n",
        "            elementsweight.append(j)\n",
        "            delay.append(float(w))\n",
        "        if float(totalweight) < float(BestPath):\n",
        "            BestPath = totalweight\n",
        "            ControllerLocation = i\n",
        "            nwl = elementsweight\n",
        "            PropagationDelay=delay\n",
        "            Hops=count\n",
        "        #print(lista.index(i))\n",
        "        #print(BestPath)\n",
        "    nwl.insert(0, ControllerLocation)\n",
        "    Hops.insert(0, 1)\n",
        "    PropagationDelay.insert(0, 0)\n",
        "    #print(Hops[2])\n",
        "    #print(PropagationDelay[2])\n",
        "    return nwl,Hops,PropagationDelay"
      ],
      "metadata": {
        "id": "G3OWfzkPV5gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reward** "
      ],
      "metadata": {
        "id": "OteoOuPvZEyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "#Reward\n",
        "\"\"\"\n",
        "Created on Wed May 11 14:54:00 2022\n",
        "\n",
        "@author: hp\n",
        "\"\"\"\n",
        "import math\n",
        "import pandas as pd\n",
        "#from shortest_path import BestControllerLocation\n",
        "\n",
        "Switches_names={0:\"ATLAM5\",1:\"ATLAng\",2:\"CHINng\",3:\"DNVRng\",4:\"HSTNng\",5:\"IPLSng\",6:\"KSCYng\",7:\"LOSAng\",8:\"NYCMng\",\n",
        "                9:\"SNVAng\",10:\"STTLng\",11:\"WASHng\"}     \n",
        "Controllers_names={12:\"c1\",13:\"c2\",14:\"c3\"}\n",
        "\n",
        "Switch_Controller = [(9,12),(6,13),(5,14)]\n",
        "pathes={0:[0,1,5,14], 1:[1,5,14], 2:[2,5,14], 3:[3,6,13], 4:[4,6,13], 5:[5,14],\n",
        "         6:[6,13], 7:[7,9,12], 8:[8,2,5,14], 9:[9,12], 10:[10,9,12], 11:[11,8,2,5,14]}\n",
        "\n",
        "Mapping = pd.DataFrame.from_dict(pathes, orient='index').transpose()\n",
        "\n",
        "listOfLongAndLatit = {0: (-84.3833, 33.75), 1: (-85.5, 34.5), 2: (-87.6167, 41.8333), \n",
        " 3: (-105.0, 40.75), 4: (-95.517364, 29.770031), 5: (-86.159535, 39.780622), \n",
        " 6: (-96.596704, 38.961694), 7: (-118.25, 34.05), 8: (-73.9667, 40.7833), 9: (-122.02553, 37.38575), \n",
        " 10: (-122.3, 47.6), 11: (-77.026842, 38.897303), 12:(-120.85851, 39.67858333),\n",
        " 13:(-99.03802267, 36.49390833), 14:(-82.4421795, 38.25742083)}\n",
        "\n",
        "Switchestraff = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6:7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12}\n",
        "#listOfLongAndLatit = [(-84.3833,33.75),(-85.5,34.5),(-95.517364,29.770031)]\n",
        "#listOfLongAndLatit.reverse() \n",
        "Bmax = 50000\n",
        "class Reward:\n",
        "    \n",
        "    def __init__(self,hops,PropagationDelay):\n",
        "        self.hops = hops\n",
        "        self.PropagationDelay = PropagationDelay\n",
        "        #self.listOfLongAndLatit = listOfLongAndLatit\n",
        "        #self.NumOfSwitches = NumOfSwitches\n",
        "        #self.Mapping = Mapping\n",
        "        #self.NumOfControllers = NumOfControllers\n",
        "    \n",
        "    def processing(self):\n",
        "        processing_time = 0\n",
        "        Controller_processing_latency =0.03\n",
        "        Switch_processing_latency = 0.2\n",
        "        for x in range(self.hops):\n",
        "            processing_time +=Switch_processing_latency\n",
        "            \n",
        "        processing_time+=Controller_processing_latency\n",
        "        return processing_time\n",
        "        \n",
        "    def forwarding(self):\n",
        "        Forwarding_latency =0.2\n",
        "        forwarding_time = 0\n",
        "        for x in range(self.hops):\n",
        "            forwarding_time +=Forwarding_latency\n",
        "        return forwarding_time\n",
        "    \n",
        "    #def propagation(self):\n",
        "     #   return self.PropagationDelay\n",
        "            \n",
        "   \n",
        "    def RoundTripTime(self):\n",
        "        Trtt = 2*(self.processing()+self.forwarding()+self.PropagationDelay)\n",
        "        return Trtt\n",
        "class Flows:\n",
        "\n",
        "    #def PacketInAverageLatency(self,SwitchesInCluster,SwitchesControllerpathes,Switchestraffic):\n",
        "    def PacketInAverageLatency(path,hops,PropagationDelay,traffic):\n",
        "        TotalFlows = 0\n",
        "        Latency = 0\n",
        "        for i in range(len(hops)):\n",
        "            r = Reward(hops[i],PropagationDelay[i])\n",
        "            #print(traffic[i])\n",
        "      \n",
        "            Latency +=  r.RoundTripTime() * np.float_(traffic[i])\n",
        "            #print(Latency)\n",
        "            TotalFlows+=sum(traffic[i])\n",
        "            #print(TotalFlows)\n",
        "            #ALatency = Latency/TotalFlows\n",
        "            #print(ALatency)\n",
        "        ALatency = Latency/TotalFlows\n",
        "        return ALatency,TotalFlows\n",
        "                \n",
        "    def LoadBalance(action,ClustersNumber,state):\n",
        "        Switches_names={0:\"ATLAM5\",1:\"ATLAng\",2:\"CHINng\",3:\"DNVRng\",4:\"HSTNng\",5:\"IPLSng\",6:\"KSCYng\",7:\"LOSAng\",8:\"NYCMng\",\n",
        "                9:\"SNVAng\",10:\"STTLng\",11:\"WASHng\"}  \n",
        "        TotalALatency = 0\n",
        "        TotalFlowFluctuations = 0\n",
        "        count = 0\n",
        "        DeltaB =0\n",
        "        FlowsOfLoad = []\n",
        "        cluster = {}\n",
        "        flows=Flows\n",
        "        #reward = 0\n",
        "        for i in action:\n",
        "          #print(f\"the value of action is {i}\")\n",
        "          cluster.update(i)\n",
        "        sorted_dict = sorted(cluster.items(), key=lambda kv:(kv[1], kv[0]))    \n",
        "        cluster.clear()\n",
        "        for i,j in sorted_dict:\n",
        "            if j==count:\n",
        "                cluster.update({i:j})\n",
        "            else:\n",
        "                Path,hops,PropagationDelay = BestControllerLocation(list(cluster.keys()))\n",
        "                #for i in range(len(hops)):\n",
        "                l=[]\n",
        "                for i in Path:\n",
        "                    l.append(list(state[list(Switches_names.keys())[list(Switches_names.values()).index(i)]].values()))\n",
        "                ALatency,totalflows=flows.PacketInAverageLatency(Path,hops,PropagationDelay,l)\n",
        "                l.clear() \n",
        "                #ALatency = latency/totalflows\n",
        "                if totalflows > Bmax:\n",
        "                    return 0.1,0.1\n",
        "                FlowsOfLoad.append(totalflows)\n",
        "                TotalALatency+=ALatency\n",
        "                TotalFlowFluctuations+=totalflows\n",
        "                cluster.clear()\n",
        "                cluster.update({i:j})\n",
        "                count+=1\n",
        "        Path,hops,PropagationDelay = BestControllerLocation(list(cluster.keys()))\n",
        "        #for count in range(len(hops)):\n",
        "        l=[]\n",
        "        for i in Path:\n",
        "            l.append(list(state[list(Switches_names.keys())[list(Switches_names.values()).index(i)]].values()))           \n",
        "       \n",
        "        ALatency,totalflows=flows.PacketInAverageLatency(Path,hops,PropagationDelay,l)\n",
        "        l.clear()\n",
        "        #ALatency = latency/totalflows\n",
        "        if totalflows > Bmax:\n",
        "            return 0.1,0.1\n",
        "        FlowsOfLoad.append(totalflows)\n",
        "        TotalALatency+=ALatency\n",
        "        TotalFlowFluctuations+=totalflows\n",
        "        Lavg = TotalALatency/ClustersNumber\n",
        "        Bavg = TotalFlowFluctuations/ClustersNumber\n",
        "        for i in FlowsOfLoad:\n",
        "            DeltaB +=(i-Bavg)**2\n",
        "        DeltaB = math.sqrt(DeltaB/ClustersNumber)\n",
        "        return  Lavg,DeltaB"
      ],
      "metadata": {
        "id": "NnwcGMd6V_Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#* **Dictionary to Tensor** *"
      ],
      "metadata": {
        "id": "-7ObN4lE9MtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dictionary to Tensor\n",
        "state=[{1:2},{1:5},{2:2},{2:4}]\n",
        "def DictToTensorList(state):\n",
        "    keys=[]\n",
        "    values=[]\n",
        "    for i in state:\n",
        "        for a,b in i.items():\n",
        "            keys.append(a)\n",
        "            values.append(b)\n",
        "    ls1 = T.Tensor([keys,values])    \n",
        "    Tensor2D = ls1.H\n",
        "    #print(Tensor2D.flatten().tolist())\n",
        "    TensotToList = ls1.H.squeeze().tolist()\n",
        "    return Tensor2D.flatten().tolist()\n",
        "#print(DictToTensorList(state))\n",
        "'''\n",
        "r=[]\n",
        "i=0\n",
        "#for i in range(3):\n",
        "def testy(c,b):\n",
        "    i = c%b\n",
        "    r.append([])\n",
        "    r[i].append(DictToTensorList(state))\n",
        "    i+=1\n",
        "   \n",
        "testy(3,3)    \n",
        "print(r[0])\n",
        "testy(3,2)\n",
        "print(r[1])\n",
        "print(r)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBpsBsw3wqZ7",
        "outputId": "083591a1-5c42-472f-f2b1-4ea0a909f1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nr=[]\\ni=0\\n#for i in range(3):\\ndef testy(c,b):\\n    i = c%b\\n    r.append([])\\n    r[i].append(DictToTensorList(state))\\n    i+=1\\n   \\ntesty(3,3)    \\nprint(r[0])\\ntesty(3,2)\\nprint(r[1])\\nprint(r)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#* **MultiList Dictionary to Tensor** *\n"
      ],
      "metadata": {
        "id": "7jchUeIAbfjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MultiList Dictionary to Tensor \n",
        "def MultiListDictToTensorList(state):\n",
        "    keys=[]\n",
        "    values=[]\n",
        "    for i in state:\n",
        "      for j in i:\n",
        "        for a,b in j.items():\n",
        "            keys.append(a)\n",
        "            values.append(b)\n",
        "    ls1 = T.Tensor([keys,values])    \n",
        "    Tensor2D = ls1.H\n",
        "    #print(Tensor2D.flatten().tolist())\n",
        "    TensotToList = ls1.H.squeeze().tolist()\n",
        "    return Tensor2D.tolist()"
      ],
      "metadata": {
        "id": "pFLw7dFobgWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#* **Dictionary to Tensor Action** *\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ctcQ2G4PsBHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dictionary to Tensor Action\n",
        "Switches_names={0:\"ATLAM5\",1:\"ATLAng\",2:\"CHINng\",3:\"DNVRng\",4:\"HSTNng\",5:\"IPLSng\",6:\"KSCYng\",7:\"LOSAng\",8:\"NYCMng\",\n",
        "                9:\"SNVAng\",10:\"STTLng\",11:\"WASHng\"}\n",
        "def DictToTensorAction(state):\n",
        "    keys = []\n",
        "    values = []\n",
        "    names = {}\n",
        "    for i in state:\n",
        "        for a,b in i.items():\n",
        "            keys.append(a)\n",
        "            values.append(b)\n",
        "    df = pd.DataFrame(keys,columns=['k'])\n",
        "    for i in keys:\n",
        "      names.update({i:list(Switches_names.keys())[list(Switches_names.values()).index(i)]})\n",
        "    df['k'] = df['k'].replace(names)\n",
        "    ls1 = T.Tensor([df['k'],values])\n",
        "    Tensor2D = ls1.H\n",
        "    #print(Tensor2D.flatten().tolist())\n",
        "    TensotToList = ls1.H.squeeze().tolist()\n",
        "    return Tensor2D.flatten().tolist()\n",
        "\n",
        "#print(DictToTensorAction(action))"
      ],
      "metadata": {
        "id": "AvM8mwPBQM6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action = [{'ATLAM5': 1}, {'ATLAng': 1}, {'CHINng': 2}, {'DNVRng': 2}, {'HSTNng': 1}, {'IPLSng': 1}, {'KSCYng': 2}, {'LOSAng': 2}, {'NYCMng': 2}, {'SNVAng': 2}, {'STTLng': 1}, {'WASHng': 0}]\n",
        "#print(DictToTensorAction(action))\n",
        "#print(action)\n",
        "'''\n",
        "s=DictToTensorAction(action)\n",
        "t= T.Tensor(s)\n",
        "t=t.flatten().tolist()\n",
        "w[0]=t\n",
        "print(w[0])\n",
        "'''"
      ],
      "metadata": {
        "id": "LVJrCeNq8gr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57af8a4-6007-4d1e-8ccd-6e0deb92dc86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ns=DictToTensorAction(action)\\nt= T.Tensor(s)\\nt=t.flatten().tolist()\\nw[0]=t\\nprint(w[0])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dictionary To Two Lists**"
      ],
      "metadata": {
        "id": "iGtwZaz86myz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dictionary To Two Lists\n",
        "state=[{1:2},{1:5},{2:2},{2:4}]\n",
        "def DictToTwoLists(state):\n",
        "    keys=[]\n",
        "    values=[]\n",
        "    for i in state:\n",
        "        for a,b in i.items():\n",
        "            keys.append(a)\n",
        "            values.append(b)\n",
        "    ls1 = T.Tensor(values) \n",
        "    #ls2 = T.Tensor(keys)\n",
        "    ls2 = keys\n",
        "    #Tensor2D = ls1.H\n",
        "    #print(Tensor2D.flatten().tolist())\n",
        "    #TensotToList = ls1.H.squeeze().tolist()\n",
        "    return ls1.tolist(),ls2\n",
        "'''\n",
        "x,y = DictToTwoLists(state)\n",
        "print(x,y)\n",
        "s=[]\n",
        "y=y\n",
        "x=x\n",
        "for i,j in zip(y , x):\n",
        "    s.append({i:j})\n",
        "print(s)\n",
        "'''"
      ],
      "metadata": {
        "id": "FJrBkMnP6wCT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0640603e-8afe-4758-852a-c8dc69168847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nx,y = DictToTwoLists(state)\\nprint(x,y)\\ns=[]\\ny=y\\nx=x\\nfor i,j in zip(y , x):\\n    s.append({i:j})\\nprint(s)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DQN Pytorch**"
      ],
      "metadata": {
        "id": "XXERaiawZvKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Jul 22 14:45:31 2022\n",
        "\n",
        "@author: hp\n",
        "\"\"\"\n",
        "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "CUDA_LAUNCH_BLOCKING = \"1\"\n",
        "global Call\n",
        "\n",
        "class DeepQNetwork(nn.Module):\n",
        "    def __init__(self,lr,input_dims,fc1_dims,fc2_dims,n_actions):\n",
        "        super(DeepQNetwork, self).__init__()\n",
        "        self.input_dims = input_dims\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.n_actions = n_actions\n",
        "        \n",
        "        self.fc1 = nn.Linear(2, 64)\n",
        "        nn.init.xavier_uniform(self.fc1.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        nn.init.xavier_uniform(self.fc2.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        nn.init.xavier_uniform(self.fc3.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        self.fc4 = nn.Linear(32, 3)\n",
        "        nn.init.xavier_uniform(self.fc4.weight.data, gain=nn.init.calculate_gain('linear'))\n",
        "        self.fc5 = nn.Linear(24, 64)\n",
        "        nn.init.xavier_uniform(self.fc1.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        self.fc6 = nn.Linear(32, 1)\n",
        "        nn.init.xavier_uniform(self.fc4.weight.data, gain=nn.init.calculate_gain('linear'))\n",
        "\n",
        "\n",
        "        self.fc11 = nn.Linear(24, 64)\n",
        "        nn.init.xavier_uniform(self.fc11.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        self.fc22 = nn.Linear(64, 64)\n",
        "        nn.init.xavier_uniform(self.fc22.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        self.fc33 = nn.Linear(64, 64)\n",
        "        nn.init.xavier_uniform(self.fc33.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        self.fc44 = nn.Linear(64, 64)\n",
        "        nn.init.xavier_uniform(self.fc44.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        self.fc55 = nn.Linear(64, 1)\n",
        "        nn.init.xavier_uniform(self.fc55.weight.data, gain=nn.init.calculate_gain('linear'))\n",
        "        self.fc66 = nn.Linear(64, 1)\n",
        "        nn.init.xavier_uniform(self.fc66.weight.data, gain=nn.init.calculate_gain('linear'))\n",
        "\n",
        "\n",
        "        self.double()\n",
        "        self.optimizer = optim.Adam(self.parameters(),lr=lr)\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "        self.to(self.device)\n",
        "        \n",
        "    def forward(self,state):\n",
        "        state = state.double()\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        actions = self.fc4(x)\n",
        "        return actions\n",
        "    \n",
        "    def forward2(self,state):\n",
        "        x = F.relu(self.fc5(state))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        actions = self.fc6(x)\n",
        "        return actions\n",
        "\n",
        "    def forward3(self,state):\n",
        "        x = F.relu(self.fc11(state))\n",
        "        x = F.relu(self.fc22(x))\n",
        "        v = F.relu(self.fc33(x))\n",
        "        a = F.relu(self.fc44(x))\n",
        "        v = self.fc55(v)\n",
        "        a = self.fc66(a)\n",
        "        x = v.expand(v.size(0), 1) + a - a.mean(1).unsqueeze(1).expand(a.size(0), 1)\n",
        "        return x\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self,n,n_actions,ActionSpace,gamma,epsilon,lr,input_dims,batch_size,\n",
        "                mem_size=100_000,eps_end=0.02,eps_dec=10_000):\n",
        "        \n",
        "        #self.action_sapce = [i for i in range(n_actions)]  #My Modify\n",
        "        self.NumOfSwitches = n\n",
        "        self.action_space = ActionSpace\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.eps_dec = eps_dec\n",
        "        self.eps_min = eps_end \n",
        "        self.lr = lr\n",
        "        self.mem_size = mem_size\n",
        "        self.batch_size = batch_size\n",
        "        self.mem_cntr = 0\n",
        "        self.Q_eval = DeepQNetwork(self.lr,n_actions=n_actions,input_dims=input_dims,fc1_dims=64\n",
        "                                   ,fc2_dims=64) #n_actions\n",
        "        #self.state_memory = np.zeros((self.mem_size,*input_dims),dtype=np.float64)\n",
        "        #self.new_state_memory = np.zeros((self.mem_size,*input_dims),dtype=np.float64)\n",
        "        #self.action_memory = np.zeros((self.mem_size,*input_dims),dtype=np.float64)\n",
        "        #self.reward_memory = np.zeros(self.mem_size,dtype=np.float64)\n",
        "        self.state_memory = np.zeros((self.mem_size,*input_dims),dtype=np.float64)\n",
        "        self.new_state_memory = np.zeros((self.mem_size,*input_dims),dtype=np.float64)\n",
        "        self.action_memory = np.zeros((self.mem_size,*input_dims),dtype=np.float64)\n",
        "        self.reward_memory = np.zeros(self.mem_size,dtype=np.float64)\n",
        "        self.terminal_memory = np.zeros(self.mem_size,dtype=bool)\n",
        "      \n",
        "    def choose_action(self,observation):\n",
        "        if np.random.random() < self.epsilon: # 0.02 instead of np.random.random() knowing that length of done must be over than the number of choosing random actions\n",
        "            action = randomchoice(self.action_space)\n",
        "            #x=0\n",
        "            #print(\" action in choose action = \"+ str(action))\n",
        "        \n",
        "        else:\n",
        "            action = []\n",
        "            #observation,x = DictToTwoLists(observation)\n",
        "            observation = DictToTensorList(observation)#######################################################################\n",
        "            state = T.tensor([observation]).to(self.Q_eval.device)\n",
        "            count = 0\n",
        "            for i in range(0,self.NumOfSwitches*2,2):############################################################################\n",
        "              print(f\"state[0]{[i]} in choose action  = {state[0][i:i+2]}\")\n",
        "              actions = self.Q_eval.forward(state[0][i:i+2].unsqueeze(dim= 0))###################################################\n",
        "              print(f\"actions[0]{[i]} is {actions}\")\n",
        "              action.append({Switches_names[count]:T.argmax(actions).item()}) #################################################\n",
        "              print(f\"action[0]{[i]} is {action}\")  \n",
        "              count +=1\n",
        "            '''\n",
        "            action = []\n",
        "            #print(observation)\n",
        "            #state = T.tensor([observation]).to(self.Q_eval.device) # i think their will be a problem here\n",
        "            #observation = DictToTensorList(observation)\n",
        "            observation,x = DictToTwoLists(observation)\n",
        "            print(\"observation in choose action = \"+str(observation.size()))\n",
        "            state = T.tensor([observation]).to(self.Q_eval.device)\n",
        "            print(\"state size in choose action = \"+str(state.size()))\n",
        "            actions = self.Q_eval.forward(state)\n",
        "            #print(\"actions.H in choose action = \"+str(actions.H))\n",
        "            #error may occur \n",
        "            for i in actions:\n",
        "                action.append(T.argmax(actions).item())\n",
        "            #print(\"len of action in choose action = \"+str(len(action)))\n",
        "            '''\n",
        "        return action #########################################################################\n",
        "\n",
        "    def store_transition(self,state,action,reward,state_,done):\n",
        "        index = self.mem_cntr % self.mem_size\n",
        "        #print(f\"state = {state}\")\n",
        "        #print(f\"action = {action}\")\n",
        "        self.state_memory[index] = DictToTensorList(state)\n",
        "        #self.state_memory[index],xs = DictToTwoLists(state)\n",
        "        #print(f\"store_transition: state_memory length = {len(self.state_memory[index])}\")\n",
        "        self.new_state_memory[index] = DictToTensorList(state_)\n",
        "        #self.new_state_memory[index],xs_ = DictToTwoLists(state_)\n",
        "        #print(f\"new_state_memory = {self.new_state_memory}\") #may a problem where the newstate and state not changed\n",
        "        self.action_memory[index] = DictToTensorAction(action)\n",
        "        #self.action_memory[index],xA = DictToTwoLists(action)\n",
        "        self.reward_memory[index] = reward\n",
        "        self.terminal_memory[index] = done\n",
        "        self.mem_cntr +=1\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    def learn(self):\n",
        "        if self.mem_cntr < self.batch_size:\n",
        "            return\n",
        "        \n",
        "        self.Q_eval.optimizer.zero_grad()\n",
        "\n",
        "        max_mem = min(self.mem_cntr, self.mem_size)\n",
        "        print(f\"learn max_mem = {max_mem}\")\n",
        "        batch = np.random.choice(max_mem, self.batch_size, replace=False)\n",
        "        #print(f\"learn batch = {batch}\")\n",
        "        batch_index = np.arange(self.batch_size, dtype=np.int64)\n",
        "        state_batch = T.tensor(self.state_memory[batch]).to(self.Q_eval.device)\n",
        "        print(\"learn state_batch size = \"+str(state_batch.size()))\n",
        "        new_state_batch = T.tensor(self.new_state_memory[batch]).to(self.Q_eval.device)\n",
        "        action_batch = self.action_memory[batch]\n",
        "        reward_batch = T.tensor(self.reward_memory[batch]).to(self.Q_eval.device)\n",
        "        terminal_batch = T.tensor(self.terminal_memory[batch]).to(self.Q_eval.device)\n",
        "        #print(f\"the state_batch size is {state_batch.size()}\")\n",
        "        #print(f\"learn the batch_index is {batch_index}\")\n",
        "        #print(f\"learn the action_batch is {action_batch}\")\n",
        "        #q_eval=self.Q_eval.forward(state_batch)[batch_index, action_batch]\n",
        "        \n",
        "        #print(f\"learn state_batch[j]{[j]} = { state_batch[j][i:i+2]}\")\n",
        "        q_eval = self.Q_eval.forward3(state_batch)#[batch_index,action_batch]#[0, 1]########################################################\n",
        "        q_next = self.Q_eval.forward3(new_state_batch)#################################################################\n",
        "        #print(f\"learn terminal_batch = {terminal_batch}\")\n",
        "        #print(f\"learn q_next = {q_next}\")\n",
        "        q_next[terminal_batch] = 0.0\n",
        "        #q_target.append(reward_batch + self.gamma*T.max(q_next, dim=1)[0])###################################################\n",
        "        q_target = reward_batch + self.gamma*T.max(q_next)\n",
        "        #print(f\"learn q_next after = {q_next}\")\n",
        "        #print(f\"learn q_target  = {q_target}\")\n",
        "        \n",
        "        #loss = self.Q_eval.loss(q_target.float(), q_eval.float()).to(self.Q_eval.device)######################################\n",
        "        #print(f\"learn q_eval len  = {len(q_eval)}\")\n",
        "        loss = self.Q_eval.loss(q_target,q_eval).to(self.Q_eval.device)\n",
        "        #loss = criterion(model_prediction.float(), target_variable.float())\n",
        "        loss.backward()########################################################################################################\n",
        "        self.Q_eval.optimizer.step() #may should be inside the loop\n",
        "        print(f\"loss = {loss}\")\n",
        "        #self.iter_cntr += 1\n",
        "        self.epsilon = self.epsilon - self.eps_dec \\\n",
        "            if self.epsilon > self.eps_min else self.eps_min\n",
        "            \n",
        "# Q_eval"
      ],
      "metadata": {
        "id": "Uit4AB3OaAy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testaya\n",
        "#print(np.random.choice(4,4,replace = False))\n",
        "#print(f\"arrange = {np.arange(4, dtype=np.int64)}\")\n",
        "test1 = T.tensor([1,2,3,4])\n",
        "test2 = T.tensor([4,8,2,3])\n",
        "#print(f\"T.max = {T.max(T.max(test1,test2))}\")\n",
        "loss = nn.MSELoss()\n",
        "device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "d1=T.tensor(1.4)#[1,2,3]\n",
        "d2=T.tensor(3)#[4,5,6]\n",
        "lossy = loss(d1.float(), d2.float()).to(device)\n",
        "\n",
        "#print(f\"lossy = {lossy}\")\n",
        "#print(f\"d1.float() = {d1.float()}\")\n",
        "s = []\n",
        "t = []\n",
        "for i in range(3):\n",
        "  s.append([])\n",
        "  s[i].append(T.tensor([i,i,i]))\n",
        "\n",
        "b = np.random.choice(3, 3, replace=False)\n",
        "l =T.tensor([1,2,3])\n",
        "#print(5 + 2*T.max(l)[0])\n",
        "state_batch = [[1,2,3,4],[4,5,6,7],[7,8,9,10]]\n",
        "for j in range(3):\n",
        "      for i in range(0,4,2): \n",
        "          print(f\"learn state_batch{[j]} = { state_batch[j][i:i+2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZsEYlz1n8pL",
        "outputId": "c2f98988-4f94-4799-f8e2-ac238b1ddd1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learn state_batch[0] = [1, 2]\n",
            "learn state_batch[0] = [3, 4]\n",
            "learn state_batch[1] = [4, 5]\n",
            "learn state_batch[1] = [6, 7]\n",
            "learn state_batch[2] = [7, 8]\n",
            "learn state_batch[2] = [9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utils**"
      ],
      "metadata": {
        "id": "283WOuAHaJ7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def plotLearning(x, latency, load):\n",
        "    y = latency\n",
        "    z = load\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(x, y, color='orange', linestyle='dashed', linewidth = 2,\n",
        "         marker='X', markerfacecolor='red', markersize=10)\n",
        "    ax.set_ylabel('Latency', color=\"C0\")\n",
        "    plt.show()\n",
        "    #load balance plot\n",
        "    fig, ax2 = plt.subplots()\n",
        "    ax2.plot(x, z, color='green', linestyle='dashed', linewidth = 2,\n",
        "        marker='X', markerfacecolor='blue', markersize=10)\n",
        "    ax2.set_ylabel('Load Balance', color=\"C1\")\n",
        "    plt.show()\n",
        "#SwitchesLatency = [[10.82284513], [14.18113285]]\n",
        "#SwitchesLoad = [843.109006153129, 692.2788237834724]\n",
        "#time = [5, 10]\n",
        "#plotLearning(time,SwitchesLatency,SwitchesLoad)"
      ],
      "metadata": {
        "id": "hxIp0aOoaN7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Global Random Function **"
      ],
      "metadata": {
        "id": "CwbJool-uYMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Global Random Function \n",
        "def randomchoice(space):\n",
        "  choice=[]\n",
        "  for i in space:\n",
        "          rnd_choice = np.random.choice(i)\n",
        "          choice.append( rnd_choice)\n",
        "          #c=np.random.choice(i)\n",
        "          #state.append(c)\n",
        "          #s=np.array(state)\n",
        "  return choice\n",
        "  '''\n",
        "StateSpace = [[{0: 9.314551}, {1: 9.314551}, {2: 9.314551}],\n",
        "              [{0: 151.188115},{1: 151.188115}, {2: 151.188115}],\n",
        "              [{0: 131.828622}, {1: 131.828622},{2: 131.828622}],\n",
        "              [{0: 124.998645}, {1: 124.998645}, {2: 124.998645}],\n",
        "              [{0: 159.46923}, {1: 159.46923}, {2: 159.46923}],\n",
        "              [{0: 324.026864}, {1: 324.026864}, {2: 324.026864}],\n",
        "              [{0: 87.957416}, {1: 87.957416}, {2: 87.957416}],\n",
        "              [{0: 328.540483}, {1: 328.540483}, {2: 328.540483}],\n",
        "              [{0: 461.294549}, {1: 461.294549}, {2: 461.294549}],\n",
        "              [{0: 33.413244}, {1: 33.413244}, {2: 33.413244}],\n",
        "              [{0: 121.985259}, {1: 121.985259}, {2: 121.985259}],\n",
        "              [{0: 607.703116}, {1: 607.703116}, {2: 607.703116}]]\n",
        "              '''\n",
        "#print(f\"random choices : {randomchoice(StateSpace)}\")\n",
        "'''\n",
        "  choice=[]\n",
        "  for i in sapce:\n",
        "      for j in i:\n",
        "          rnd_indices = np.random.choice(len(j))\n",
        "          choice.append( j[rnd_indices])\n",
        "          #c=np.random.choice(i)\n",
        "          #state.append(c)\n",
        "          #s=np.array(state)\n",
        "          '''"
      ],
      "metadata": {
        "id": "n-ud_Nnd5Vtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c21447-c89d-4b92-ef3f-146c93e27c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  choice=[]\\n  for i in sapce:\\n      for j in i:\\n          rnd_indices = np.random.choice(len(j))\\n          choice.append( j[rnd_indices])\\n          #c=np.random.choice(i)\\n          #state.append(c)\\n          #s=np.array(state)\\n          '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Environment**\n"
      ],
      "metadata": {
        "id": "hrb2XGhwnFnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Jul 20 21:49:02 2022\n",
        "\n",
        "@author: hp\n",
        "\"\"\"\n",
        "#Custom Environment\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "#from reward import LoadBalance\n",
        "#from DQN_Pytorch import Agent\n",
        "#from utils import plotLearning\n",
        "#from reward import PacketInAverageLatency\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# parameters taken from the second paper\n",
        "Minibatch_size = 64\n",
        "Replay_buffer_size = 1000_000\n",
        "#Learning_start = 3000  \n",
        "Target_update_frequency = 10_000\n",
        "Learning_rate = 0.0001\n",
        "\n",
        "# parameters taken from videos\n",
        "\n",
        "discount_rate = 0.95  #discont factor\n",
        "Epsilon_start = 1\n",
        "Epsilon_end = 0.02 #used in colab\n",
        "Epsilon_decay = 10_000 #used in colab\n",
        "mem_size = 100_000 #used in colab\n",
        "\n",
        "#mine \n",
        "\n",
        "theta = 0.3\n",
        "theta_ = theta\n",
        "action_memory = np.zeros(mem_size,dtype=np.int64)\n",
        "target_action_memory = action_memory\n",
        "\n",
        "class SDNEnv(Env):\n",
        "    def __init__(self,n,k,StateSpace,ActionSpace):\n",
        "        # Actions we can take, down, stay, up\n",
        "        \n",
        "        self.ClustersNum = k\n",
        "        self.SwitchesNum = n\n",
        "        self.action_space = ActionSpace\n",
        "        # Temperature array\n",
        "        #self.observation_space = Box(low=np.array([0]), high=np.array([10]))\n",
        "        #self.observation_space = Box(low=np.array([0]), high=np.array([10]),dtype= np.float128)\n",
        "        # Set start temp        \n",
        "        self.statespace = StateSpace\n",
        "        # Set shower length\n",
        "        self.length = 64\n",
        "        self.state = randomchoice(StateSpace)\n",
        "    def step(self, action):\n",
        "        # Apply action\n",
        "        \n",
        "        #self.state += action -1 \n",
        "        #c = []\n",
        "        count=0\n",
        "        NewState = []\n",
        "        #NewState.append([])\n",
        "        '''\n",
        "        if x:\n",
        "            actiontemp=action\n",
        "            action=[]\n",
        "            for i,j in zip(actiontemp , x):\n",
        "                action.append({i:j})\n",
        "               '''\n",
        "        c = action\n",
        "        #print(\"action in step = \"+ str(action))\n",
        "        for i in self.state:            \n",
        "            #c = action\n",
        "            #print(c)\n",
        "            NewState.append({list(c[count].values())[0]: list(i.values())[0]})  #output:[{1: 2222}, {0: 5555}, {1: 7777}, {2: 8888}]\n",
        "            count+=1\n",
        "        #print(f\"step NewState = {NewState}\")\n",
        "        #print(count)\n",
        "        #print(f\"new state {NewState}\")\n",
        "               \n",
        "        '''\n",
        "        for i in self.statespace:\n",
        "            NewState.append(np.random.choice(i))\n",
        "        '''\n",
        "        # Reduce shower length by 1 second\n",
        "        self.length -= 1 \n",
        "        #print(\"length = \"+str(self.length))\n",
        "        # Calculate reward\n",
        "        #count = 0\n",
        "        f = Flows\n",
        "        latency,load = f.LoadBalance(action,self.ClustersNum,NewState)\n",
        "        reward = -((0.5*latency)+(0.5*load))\n",
        "        #print(f\"Reward = {reward}\")\n",
        "        # Check if shower is done\n",
        "\n",
        "        if self.length <= 0: \n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "          \n",
        "          \n",
        "        #done=False\n",
        "        \n",
        "        # Apply temperature noise\n",
        "        #self.state += random.randint(-1,1)\n",
        "        # Set placeholder for info\n",
        "        info = {}\n",
        "        \n",
        "        # Return step information\n",
        "        return NewState, reward, done, info, latency, load\n",
        "    \n",
        "    def render(self):\n",
        "        # Implement viz\n",
        "        pass\n",
        "    \n",
        "    def reset(self):\n",
        "        # Reset shower temperature\n",
        "        #state = []\n",
        "        #for i in self.statespace:\n",
        "          #state.append(np.random.choice(i))\n",
        "        self.state = randomchoice(self.statespace)\n",
        "        #print(f\"reset self.state = {self.state}\")\n",
        "        # Reset shower time\n",
        "        self.length = 64\n",
        "\n",
        "        return self.state\n",
        "\n",
        "\n",
        "class Deployment:\n",
        "    \n",
        "    #env = gym.make('LunarLander-v2')\n",
        "    def run(n,k,StateSpace,ActionSpace):\n",
        "        \n",
        "#        self.n_switches = n_switches\n",
        " #       action = {}\n",
        "  #      for i in range(n_switches):          \n",
        "   #       action.update({i:random.choice(range(1,k+1))})\n",
        "        #n_actions = k\n",
        "        n_actions = n\n",
        "        agent = Agent(n,n_actions,ActionSpace,gamma=0.95, epsilon=1.0, lr=0.0001,input_dims=[n*2],\n",
        "                      batch_size=64)\n",
        "       # scores, eps_history = [], []\n",
        "        SwitchesLatency, SwitchesLoad = [], []\n",
        "        n_games = 100 #on 2nd paper\n",
        "        for i in range(n_games):\n",
        "            print(\"i = \"+str(i))\n",
        "            Latencyscore = 0\n",
        "            Loadscore = 0\n",
        "            done = False\n",
        "            env = SDNEnv(n,k,StateSpace,ActionSpace)\n",
        "            observation = env.reset()\n",
        "            while not done:\n",
        "                #print(\"observation \"+str(observation))\n",
        "                #observation [{0: 9.314551}, {1: 151.188115}, {1: 131.828622}, {1: 124.998645},\n",
        "                #{1: 159.46923}, {0: 324.026864}, {2: 87.957416}, {2: 328.540483}, \n",
        "                #{2: 461.294549}, {2: 33.413244}, {2: 121.985259}, {1: 607.703116}]\n",
        "                #action,x = agent.choose_action(observation)\n",
        "                action = agent.choose_action(observation)\n",
        "                #print(f\"x= {x}\")\n",
        "                #print(\"len of action \"+str(len(action)))\n",
        "                observation_, reward, done, info, latency, load = env.step(action)\n",
        "                #print(\"len of observation_ \"+str(len(observation_)))\n",
        "                #print(f\"state in custom is {observation}\")\n",
        "                agent.store_transition(observation, action, reward, \n",
        "                                        observation_, done)\n",
        "                agent.learn()\n",
        "                observation = observation_\n",
        "                Latencyscore += latency\n",
        "                Loadscore += load\n",
        "            #scores.append(score)\n",
        "                SwitchesLatency.append(latency)\n",
        "                SwitchesLoad.append(load)\n",
        "            \n",
        "            #avg_score = np.mean(scores[-100:])\n",
        "    \n",
        "            print('episode ', i,'latency %.2f' % Latencyscore,\n",
        "                    'load %.2f' % Loadscore)\n",
        "        #x = [i+1 for i in range(n_games)]\n",
        "        #x += 5\n",
        "        #filename = 'lunar_lander.png'\n",
        "        #plotLearning(x, latency, load)\n",
        "        return latency ,load"
      ],
      "metadata": {
        "id": "9glhmVvlmO-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main**"
      ],
      "metadata": {
        "id": "oypNSbtladQw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x0KYoHfVWg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "c5450052-caf3-43be-a99d-a76f91015155"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3b55dac25ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#from CustomEnvironment import custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positions.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'positions.csv'"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed May 11 10:33:39 2022\n",
        "\n",
        "@author: hp\n",
        "\"\"\"\n",
        "#Main\n",
        "#import os\n",
        "import pandas as pd\n",
        "\n",
        "from collections import deque\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd \n",
        "CUDA_LAUNCH_BLOCKING = \"1\"\n",
        "\n",
        "Switches_names={0:\"ATLAM5\",1:\"ATLAng\",2:\"CHINng\",3:\"DNVRng\",4:\"HSTNng\",5:\"IPLSng\",6:\"KSCYng\",7:\"LOSAng\",8:\"NYCMng\",\n",
        "                9:\"SNVAng\",10:\"STTLng\",11:\"WASHng\"}  \n",
        "\n",
        "#from CustomEnvironment import custom\n",
        "\n",
        "df= pd.read_csv(\"positions.csv\")\n",
        "source = df['source']\n",
        "target = df['target']\n",
        "SwitchesMapping =[]\n",
        "ControllersMapping=[(12,13),(13,14)]\n",
        "for x,y in zip(source,target):\n",
        "    Tuple=(x,y)\n",
        "    SwitchesMapping.append(Tuple)\n",
        "    \n",
        "\n",
        "#The first algorithm\n",
        "number = 0\n",
        "k=3\n",
        "W = w = 12\n",
        "StateSpace = []\n",
        "ActionSpace = []\n",
        "counter = 0\n",
        "df = pd.read_excel('MergeTest.xlsx')\n",
        "traffic = df['traffic']\n",
        "df = df.reset_index()\n",
        "#for item , row in df.iterrows():\n",
        "D = Deployment\n",
        "iterations=0\n",
        "x=0\n",
        "SwitchesLatency, SwitchesLoad, time = [], [], []\n",
        "#prepare the state sequence\n",
        "for i in range(0,len(traffic),W): #change def to traffic \n",
        "    while number < W :\n",
        "        StateSpace.append([]) \n",
        "        ActionSpace.append([])\n",
        "        # action list will be  [[{switch1--> 'ATLAM5':clusternumber -->0},{0:1},{0:2}],\n",
        "        #                        [{switch2-->'ATLAng':clusternumber -->0},{1:1},{2:1}]\n",
        "        #                        [                                            ]...12]\n",
        "        for j in range(k):\n",
        "            ActionSpace[counter].append({list(Switches_names.values())[counter]:j})  #list(Switches_names.values())[counter] instead of counter\n",
        "            \n",
        "            \n",
        "        for controller in range(k):\n",
        "            StateSpace[counter].append({controller:df.loc[number, \"traffic\"]})\n",
        "            \n",
        "        number+=1\n",
        "        counter+=1\n",
        "    #print(f\"action {action}\")\n",
        "    iterations+=1\n",
        "    print(f\"iteration {iterations}\")\n",
        "    #print(f\"StateSpace = {StateSpace}\")\n",
        "    #print(action)   \n",
        "    W+= w\n",
        "    counter=0\n",
        "             \n",
        "    latency , load = D.run(w,k,StateSpace,ActionSpace)\n",
        "    SwitchesLatency.append(latency)\n",
        "    SwitchesLoad.append(load)\n",
        "    x += 5\n",
        "    time.append(x)\n",
        "    #custom(SS,discount_rate,Epsilon_start,Epsilon_end,Epsilon_decay)\n",
        "    #custom(w,k,StateSpace,ActionSpace)\n",
        "    \n",
        "    #print(SS)\n",
        "    StateSpace.clear()\n",
        "    ActionSpace.clear()\n",
        "print(f\"SwitchesLatency = {SwitchesLatency}\")\n",
        "print(f\"SwitchesLoad = {SwitchesLoad}\")\n",
        "print(f\"time = {time}\")\n",
        "\n",
        "plotLearning(time, SwitchesLatency, SwitchesLoad)        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc1 = nn.Linear(4, 64)\n",
        "nn.init.xavier_uniform(fc1.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "fc2 = nn.Linear(64, 64)\n",
        "nn.init.xavier_uniform(fc2.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "fc3 = nn.Linear(64, 32)\n",
        "nn.init.xavier_uniform(fc3.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "fc4 = nn.Linear(32, 3)\n",
        "nn.init.xavier_uniform(fc4.weight.data, gain=nn.init.calculate_gain('linear'))\n",
        "fc5 = nn.Linear(24, 64)\n",
        "nn.init.xavier_uniform(fc1.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "fc6 = nn.Linear(32, 1)\n",
        "nn.init.xavier_uniform(fc4.weight.data, gain=nn.init.calculate_gain('linear'))\n",
        "\n",
        "fc11 = nn.Linear(4, 64)\n",
        "nn.init.xavier_uniform(fc11.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "fc22 = nn.Linear(64, 64)\n",
        "nn.init.xavier_uniform(fc22.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "fc33 = nn.Linear(64, 64)\n",
        "nn.init.xavier_uniform(fc33.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "fc44 = nn.Linear(64, 64)\n",
        "nn.init.xavier_uniform(fc44.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "fc55 = nn.Linear(64, 1)\n",
        "nn.init.xavier_uniform(fc55.weight.data, gain=nn.init.calculate_gain('linear'))\n",
        "fc66 = nn.Linear(64, 3)\n",
        "nn.init.xavier_uniform(fc66.weight.data, gain=nn.init.calculate_gain('linear'))\n",
        "\n",
        "def forward(state):\n",
        "        state = state.double()\n",
        "        x = F.relu(fc1(state))\n",
        "        x = F.relu(fc2(x))\n",
        "        x = fc3(x)\n",
        "        actions = fc4(x)\n",
        "        return actions\n",
        "    \n",
        "def forward2(state):\n",
        "    x = F.relu(fc5(state))\n",
        "    x = F.relu(fc2(x))\n",
        "    x = F.relu(fc3(x))\n",
        "    actions = fc6(x)\n",
        "    return actions\n",
        "\n",
        "\n",
        "def forward3(state):\n",
        "    state = state.float()\n",
        "    x = F.relu(fc11(state))\n",
        "    x = F.relu(fc22(x))\n",
        "    v = F.relu(fc33(x))\n",
        "    a = F.relu(fc44(x))\n",
        "    v = fc55(v)\n",
        "    a = fc66(a)\n",
        "    x = v.expand(v.size(0), -1) + a - a.mean(-1).unsqueeze(-1).expand(a.size(0), -1)\n",
        "    return x\n",
        "z = T.tensor([1,2,1,3,1,4,2,5,2,6,3,7,3,8,3,9,1,1,2,10,1,11,3,12])\n",
        "x1 = forward(z[0:4])\n",
        "x2 = forward(z[4:8])\n",
        "x3 = forward(z[8:12])\n",
        "print(x1)\n",
        "print(x2)\n",
        "print(x3)\n",
        "print(\"**********\")\n",
        "print(T.max(x1))\n",
        "print(T.max(x2))\n",
        "print(T.max(x3))\n",
        "print(\"**********\")\n",
        "print(T.argmax(x1))\n",
        "print(T.argmax(x2))\n",
        "print(T.argmax(x3))\n"
      ],
      "metadata": {
        "id": "UicTh7VZxxaR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "e93a5a6a-554d-4b8f-9315-3e76cb08205c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-60099b6ac157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'state'"
          ]
        }
      ]
    }
  ]
}